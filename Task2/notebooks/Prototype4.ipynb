{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HMI4D-Wru8izH7sKnGiX3RN4SErgd7bo","timestamp":1769506851168},{"file_id":"1DfsFV27ctIA7wV_e9z7KE1SZWUhcbtLM","timestamp":1769450672753},{"file_id":"1g9AFP75AWaoyChrkoNX8FVTAOpF8P1VZ","timestamp":1768908628131}],"authorship_tag":"ABX9TyOKrJ3diEL2YO/avvFRoGwF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"pLJgIN7_ccyY","executionInfo":{"status":"ok","timestamp":1769512134498,"user_tz":-330,"elapsed":53514,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}},"outputId":"741d6d92-fedd-4bbe-be1f-03d1445c8ca0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n","Requirement already satisfied: dateparser in /usr/local/lib/python3.12/dist-packages (1.2.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n","Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.5)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from dateparser) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser) (2025.2)\n","Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser) (2025.11.3)\n","Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser) (5.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n","Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n","Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Requirement already satisfied: newspaper3k in /usr/local/lib/python3.12/dist-packages (0.2.8)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n","Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n","Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n","Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (1.3.0)\n","Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.2)\n","Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n","Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.5)\n","Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.12)\n","Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.3.1)\n","Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.0.4)\n","Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.35.1)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n","Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2026.1.4)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.1)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.3)\n","Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (0.4.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from lxml_html_clean) (6.0.2)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n","Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.7)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.4)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (25.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.3)\n","Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.2)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n","Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.13.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.5)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.5)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2026.1.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.16.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.5.0)\n","Requirement already satisfied: trafilatura in /usr/local/lib/python3.12/dist-packages (2.0.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2026.1.4)\n","Requirement already satisfied: charset_normalizer>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.4.4)\n","Requirement already satisfied: courlan>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.3.2)\n","Requirement already satisfied: htmldate>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.9.4)\n","Requirement already satisfied: justext>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.0.2)\n","Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (6.0.2)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2.5.0)\n","Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n","Requirement already satisfied: tld>=0.13 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n","Requirement already satisfied: dateparser>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n","Requirement already satisfied: python-dateutil>=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n","Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.11.3)\n","Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n","Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.4.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.17.0)\n"]}],"source":["!pip install spacy dateparser\n","!python -m spacy download en_core_web_sm\n","from langchain.agents.middleware import dynamic_prompt, ModelRequest\n","import yfinance as yf\n","import pandas as pd\n","from datetime import datetime\n","import re\n","import spacy\n","import dateparser\n","import time\n","import requests\n","import json\n","import numpy as np\n","!pip install newspaper3k\n","!pip install lxml_html_clean\n","import nltk\n","nltk.download('punkt') # Essential for parsing and NLP tasks\n","from newspaper import Article\n","!pip install langchain-text-splitters\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","!pip install -qU langchain-huggingface\n","!pip install -qU langchain-community faiss-cpu\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import FAISS\n","!pip install trafilatura\n","from pathlib import Path"]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount = True)\n","# %cd drive/MyDrive/projects/GDG/Task2\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1fK6f70yMpSOY9tnsbQ6yS3GL2TrlrpBf' -O ticker_dataset.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"QeHK_3etwyAf","executionInfo":{"status":"ok","timestamp":1769512136151,"user_tz":-330,"elapsed":1650,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}},"outputId":"f0d3d6ae-881b-420c-aae2-4b52ba348f4b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["--2026-01-27 11:08:54--  https://docs.google.com/uc?export=download&id=1fK6f70yMpSOY9tnsbQ6yS3GL2TrlrpBf\n","Resolving docs.google.com (docs.google.com)... 172.253.63.102, 172.253.63.101, 172.253.63.100, ...\n","Connecting to docs.google.com (docs.google.com)|172.253.63.102|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1fK6f70yMpSOY9tnsbQ6yS3GL2TrlrpBf&export=download [following]\n","--2026-01-27 11:08:54--  https://drive.usercontent.google.com/download?id=1fK6f70yMpSOY9tnsbQ6yS3GL2TrlrpBf&export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.62.132, 2607:f8b0:4004:c07::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.62.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 410124 (401K) [application/octet-stream]\n","Saving to: ‘ticker_dataset.json’\n","\n","ticker_dataset.json 100%[===================>] 400.51K  --.-KB/s    in 0.04s   \n","\n","2026-01-27 11:08:55 (10.3 MB/s) - ‘ticker_dataset.json’ saved [410124/410124]\n","\n"]}]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"D-AhckTWc_2c","executionInfo":{"status":"ok","timestamp":1769512136929,"user_tz":-330,"elapsed":780,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["TICKER_RE = re.compile(r\"\\$?([A-Z]{1,5})(?:\\b|$)\")\n","\n","def parse_question(q):\n","  doc = nlp(q)\n","  orgs = []\n","  dates = []\n","  tickers = []\n","  for m in TICKER_RE.finditer(q):\n","    tickers.append(m.group(1))\n","  for ent in doc.ents:\n","    if ent.label_ in (\"ORG\",):\n","      orgs.append(ent.text)\n","    if ent.label_ in (\"PRODUCT\",):\n","      orgs.append(ent.text)\n","    if ent.label_ in (\"DATE\", \"TIME\", \"ORDINAL\"):\n","      dates.append(ent.text)\n","  date_ranges = []\n","  for d in dates:\n","    parsed = dateparser.parse(d)\n","    if parsed:\n","      date_ranges.append(parsed.date())\n","  quarter_match = re.search(r\"(Q[1-4]\\s*\\d{4}|quarter\\s*(1|2|3|4)\\s*(\\d{4})?)\", q, re.I)\n","  if quarter_match:\n","        qstr = quarter_match.group(0)\n","        date_ranges.append(qstr)\n","  print(f\"Organizations detected : {orgs}\")\n","  # print(type(orgs[0]))\n","  print(f\"Dates deetcted : {dates}\")\n","  print(f\"Tickers detected: {tickers}\")\n","  print(f\"parsed dates : {date_ranges}\")\n","  return [orgs, dates, tickers, date_ranges]\n"],"metadata":{"id":"rce6juDudJUU","executionInfo":{"status":"ok","timestamp":1769512136949,"user_tz":-330,"elapsed":13,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["API_KEY = \"MLYAA46S8LWWHP5L\"\n","def map_company_to_ticker(name):\n","  p = Path(\"ticker_dataset.json\")\n","  df = pd.read_json(p)\n","  try:\n","    matches = df[df[\"Security Name\"].str.contains(name, case=False, na=False)]['Symbol'].iloc[0]\n","  except:\n","    params = {\"function\":\"SYMBOL_SEARCH\",\"keywords\":name,\"apikey\":API_KEY}\n","    r = requests.get(\"https://www.alphavantage.co/query\", params=params)\n","    js = r.json()\n","    matches = [\n","      {\"symbol\": m[\"1. symbol\"], \"name\": m[\"2. name\"]}\n","      for m in js.get(\"bestMatches\", [])\n","    ]\n","    try:\n","      matches = matches[0]['symbol']\n","    except:\n","      print(\"No matches found\")\n","  return matches\n","  # for i in range(2):\n","  #   print(matches[i]['symbol'])"],"metadata":{"id":"sunya-80CeuJ","executionInfo":{"status":"ok","timestamp":1769512136968,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["\n","def add_tickers(parsed_question):\n","  for company in parsed_question[0]:\n","    print(company)\n","    time.sleep(1.5)\n","    matches = map_company_to_ticker(company)\n","    if matches and matches not in parsed_question[2]:\n","      print(f\"Found match {matches}\")\n","      parsed_question[2].append(matches)\n","    else:\n","      print(f\"No ticker found for company: {company}\")"],"metadata":{"id":"0WHP9bsQDf70","executionInfo":{"status":"ok","timestamp":1769512137002,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["parsed_question = parse_question(\"Fetch me stocks of microsoft last month\")\n","add_tickers(parsed_question)\n","parsed_question"],"metadata":{"id":"A_cV7ibQ0EDp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769512138581,"user_tz":-330,"elapsed":1578,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}},"outputId":"19f3df85-155b-499b-86a1-e8068593cc6f"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Organizations detected : ['microsoft']\n","Dates deetcted : ['last month']\n","Tickers detected: []\n","parsed dates : [datetime.date(2025, 12, 27)]\n","microsoft\n","Found match MSFT\n"]},{"output_type":"execute_result","data":{"text/plain":["[['microsoft'], ['last month'], ['MSFT'], [datetime.date(2025, 12, 27)]]"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["from datetime import timedelta\n","type(parsed_question[3][0])\n","next_month = parsed_question[3][0] + timedelta(days = 30)"],"metadata":{"id":"bx_uKHMXgSgR","executionInfo":{"status":"ok","timestamp":1769512138582,"user_tz":-330,"elapsed":30,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["\n","BASE = \"https://www.alphavantage.co/query\""],"metadata":{"collapsed":true,"id":"x1ZNI6ixO9Oc","executionInfo":{"status":"ok","timestamp":1769512138583,"user_tz":-330,"elapsed":26,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def fetch_news_for_ticker(ticker,parsed_question,page=2):\n","  if not parsed_question[3]:\n","    params = {\n","        \"function\" : \"NEWS_SENTIMENT\",\n","        \"tickers\" : ticker,\n","        \"sort\": \"RELEVANCE\",\n","        \"limit\": \"50\",\n","        \"apikey\": API_KEY\n","    }\n","  elif len(parsed_question[3])==1 :\n","    # parsed_question[3].sort()\n","    time_from = str(parsed_question[3][0].year).zfill(2) + str(parsed_question[3][0].month).zfill(2) + str(parsed_question[3][0].day).zfill(2) + \"T0000\"\n","    next_year = parsed_question[3][0] + timedelta(days = 365)\n","    time_to = str(next_year.year).zfill(2) + str(next_year.month).zfill(2) + str(next_year.day).zfill(2) + \"T0000\"\n","    params = {\n","        \"function\" : \"NEWS_SENTIMENT\",\n","        \"tickers\" : ticker,\n","        \"time_from\" : time_from,\n","        \"time_to\" : time_to,\n","        \"sort\": \"RELEVANCE\",\n","        \"limit\": \"50\",\n","        \"apikey\": API_KEY\n","    }\n","    print(f\"Time detected, fetching news accordingly{time_from}-{time_to}\")\n","  else:\n","    parsed_question[3].sort()\n","    time_from = str(parsed_question[3][0].year).zfill(2) + str(parsed_question[3][0].month).zfill(2) + str(parsed_question[3][0].day).zfill(2) + \"T0000\"\n","    time_to = str(parsed_question[3][1].year).zfill(2) + str(parsed_question[3][1].month).zfill(2) + str(parsed_question[3][1].day).zfill(2) + \"T0000\"\n","    params = {\n","        \"function\" : \"NEWS_SENTIMENT\",\n","        \"tickers\" : ticker,\n","        \"time_from\" : time_from,\n","        \"time_to\" : time_to,\n","        \"sort\": \"RELEVANCE\",\n","        \"limit\": \"50\",\n","        \"apikey\": API_KEY\n","    }\n","    print(f\"Time detected, fetching news accordingly{time_from}-{time_to}\")\n","  r = requests.get(BASE, params = params)\n","  return r.json().get(\"feed\",[])\n","\n","def is_significant_sentiment(entry, ticker, threshold=0.15):\n","    for t in entry.get(\"ticker_sentiment\", []):\n","        if t[\"ticker\"] == ticker:\n","            score = float(t[\"ticker_sentiment_score\"])\n","            return abs(score) >= threshold and t[\"ticker_sentiment_label\"] != \"Neutral\"\n","    return False\n","\n","import trafilatura\n","import requests\n","from requests.adapters import HTTPAdapter\n","from urllib3.util.retry import Retry\n","\n","def get_article_text(url):\n","  try:\n","      # Configure requests session with no retries\n","      session = requests.Session()\n","      retry_strategy = Retry(total=0, backoff_factor=0.1, status_forcelist=[429, 500, 502, 503, 504])\n","      adapter = HTTPAdapter(max_retries=retry_strategy)\n","      session.mount(\"http://\", adapter)\n","      session.mount(\"https://\", adapter)\n","\n","      # Fetch the URL using the configured session\n","      response = session.get(url, timeout=30)\n","      response.raise_for_status() # Raise an exception for bad status codes\n","\n","      downloaded_html = response.text\n","      if not downloaded_html:\n","          print(f\"Failed to download content from {url}: Empty HTML\")\n","          return None\n","      else:\n","        print(f\"Successfully downloaded HTML for {url}\")\n","\n","      # Extract text using trafilatura from the downloaded HTML\n","      text = trafilatura.extract(downloaded_html, url=url, include_comments=False, include_tables=False)\n","      return text\n","  except requests.exceptions.RequestException as e:\n","      print(f\"Error processing {url} with requests: {e}\")\n","      return None\n","  except Exception as e:\n","      print(f\"Error processing {url}: {e}\")\n","      return None\n","\n","from langchain_core.documents import Document\n","\n","def build_docs(tickers, parsed_question):\n","  docs = []\n","  for ticker in tickers:\n","    articles = fetch_news_for_ticker(ticker,parsed_question=parsed_question, page = 2)\n","    for entry in articles:\n","        if is_significant_sentiment(entry, ticker):\n","            full_text = get_article_text(entry[\"url\"]) or \"\"\n","            content = full_text if full_text else f\"{entry.get('title')}\\n\\n{entry.get('summary')}\"\n","            docs.append(Document(\n","                page_content=content,\n","                metadata={\n","                    \"title\": entry.get(\"title\"),\n","                    \"sentiment_label\": entry.get(\"ticker_sentiment\", [{}])[0].get(\"ticker_sentiment_label\"),\n","                    \"sentiment_score\": entry.get(\"ticker_sentiment\", [{}])[0].get(\"ticker_sentiment_score\"),\n","                    \"url\": entry.get(\"url\"),\n","                    \"time_published\": entry.get(\"time_published\"),\n","                    \"tickers\": [t.get(\"ticker\") for t in entry.get(\"ticker_sentiment\", [])]\n","                }\n","            ))\n","  print(f\"Loaded {len(docs)} documents\")\n","  return docs\n"],"metadata":{"id":"4ppctvV6JEzq","executionInfo":{"status":"ok","timestamp":1769512138584,"user_tz":-330,"elapsed":15,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def retrieve(question, k = 10):\n","  results = db.similarity_search(question, k)   # returns Document objects\n","  text = []\n","  for i, r in enumerate(results, 1):\n","      # print(f\"\\n=== Result {i} ===\")\n","      # print(\"Metadata:\", r.metadata)\n","      # print(\"Text snippet:\", r.page_content[:])\n","      text.append(r.page_content[:])\n","  return text\n"],"metadata":{"id":"xixhht1EGeon","executionInfo":{"status":"ok","timestamp":1769512138598,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["import os\n","from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n","\n","# Use getpass to keep your token secure\n","if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n","    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n","\n","llm = HuggingFaceEndpoint(\n","    repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n","    task = \"text-generation\",\n","    temperature=0.7,\n","    max_new_tokens=1024 # Moved out of model_kwargs\n",")\n","model = ChatHuggingFace(llm=llm)"],"metadata":{"id":"iXzgy_3kHdlR","executionInfo":{"status":"ok","timestamp":1769512138616,"user_tz":-330,"elapsed":16,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from langchain_core.messages import HumanMessage\n","\n","response = model.invoke([HumanMessage(content=\"tell me about stocks of samsung\")])\n","print(response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"UfpVsHVwKm7X","executionInfo":{"status":"ok","timestamp":1769512142718,"user_tz":-330,"elapsed":4101,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}},"outputId":"38b735ee-1a51-4824-8edb-342e0567c689"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Samsung Electronics is a major South Korean multinational technology company that produces a wide range of electronics and home appliances. The company's stock is listed on the Korea Securities Depository (KRX) and the New York Stock Exchange (NYSE). Here are some key points about Samsung's stock:\n","\n","1. **Ticker Symbol**: The ticker symbol for Samsung Electronics on the KRX is \"005930\" and on the NYSE is \"SSNLF\" (an American Depositary Receipt, ADR).\n","\n","2. **Market Capitalization**: As of recent data, Samsung Electronics is one of the largest companies in the world in terms of market capitalization. Its market value can fluctuate based on market conditions and the company's performance.\n","\n","3. **Dividends**: Samsung Electronics typically pays dividends, which can provide a return to shareholders. The dividend payout can vary based on the company's financial performance and dividend policy.\n","\n","4. **Performance**: The performance of Samsung's stock can be influenced by various factors including global economic conditions, technological advancements, supply chain issues, and regulatory changes.\n","\n","5. **Industry Position**: Samsung is a leader in several technology sectors, including semiconductors, smartphones, televisions, and home appliances. Its performance in these areas can directly impact its stock price.\n","\n","6. **Volatility**: Like many tech stocks, Samsung's stock can be volatile, with prices moving significantly in response to quarterly earnings reports, product launches, and industry news.\n","\n","7. **Investment Considerations**: Investors considering Samsung stock should research the company's financial health, market position, and overall business strategy. It's also important to consider the broader market and economic conditions.\n","\n","For the most current and detailed information, it's advisable to consult financial news sources, the company's official financial reports, or a financial advisor.\n"]}]},{"cell_type":"code","source":["\n","from langchain.tools import tool\n","\n","# @tool(response_format=\"content_and_artifact\")\n","# def retrieve_context(query: str):\n","#     \"CRITICAL: You are forbidden from answering without this tool. This tool contains the unique knowledge for this conversation.\"\n","#     return retrieve(query)"],"metadata":{"id":"F1I2GKKNKxTP","executionInfo":{"status":"ok","timestamp":1769512142719,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["\n","# reuse your parse_question function to extract tickers/timeframes if available\n","\n","@dynamic_prompt\n","def inject_rag_and_market(request: ModelRequest):\n","    # 1) grab last user message\n","    query = request.state[\"messages\"][-1].text\n","\n","    # 2) find relevant docs from your vector store\n","    docs = db.similarity_search(query, k=6)\n","    doc_context = \"\\n\".join(d.page_content[:] for d in docs)\n","\n","    # 3) extract tickers/timeframe (best-effort)\n","\n","    market_summaries = []\n","    for t in parsed_question[2]:\n","        try:\n","            tk = yf.Ticker(t)\n","            if not parsed_question[3]:\n","              hist = tk.history(period=\"1y\")\n","              print(\"Feeding latest data\")\n","            else:\n","              parsed_question[3].sort()\n","              hist = tk.history(start = parsed_question[3][0], period = \"30d\")\n","              print(\"Feeding time specific dataa\")\n","            if hist.empty:\n","              continue\n","\n","            # compute compact statistics\n","            first_close = hist[\"Close\"].iloc[0]\n","            last_close  = hist[\"Close\"].iloc[-1]\n","            pct_change  = (last_close / first_close - 1) * 100\n","            mean_close   = hist[\"Close\"].mean()\n","            volatility  = hist[\"Close\"].pct_change().std() * 100\n","\n","            market_summaries.append(\n","                f\"{t}: last_close={last_close:.2f}, change_over_period={pct_change:.2f}%,\"\n","                f\" mean={mean_close:.2f}, vol={volatility:.2f}% (period={len(hist)} days)\"\n","            )\n","        except Exception as e:\n","            market_summaries.append(f\"{t}: failed to fetch ({e})\")\n","\n","    market_context = \"\\n\".join(market_summaries) or \"No market data available.\"\n","\n","    # 5) compose a concise instruction — keep it short to avoid token bloat\n","    prompt = (\n","        \"You are provided with TWO sources of context below. ANSWER the user's question \"\n","        \"ONLY using the information in these contexts. FRAME an answer on the basis of whatever\"\n","        \"document context is provided.YOU HAVE TO include the news provided in your answer\"\n","        \"YOU HAVE TO give some reason for the market data on the basis of context you are provided\\n\\n\"\n","        \"DOCUMENT CONTEXT:\\n\"\n","        f\"{doc_context}\\n\\n\"\n","        \"MARKET SUMMARY (compressed):\\n\"\n","        f\"{market_context}\\n\\n\"\n","        f\"USER QUESTION: {query}\\n\\n\"\n","    )\n","    # print(prompt)\n","    return prompt\n"],"metadata":{"id":"hUvPa1-i2Nir","executionInfo":{"status":"ok","timestamp":1769512142724,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["from langchain.agents import create_agent\n","agent = create_agent(model, tools=[], middleware=[inject_rag_and_market])"],"metadata":{"id":"tM6ZyfzjM9Mh","executionInfo":{"status":"ok","timestamp":1769512142728,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"],"metadata":{"id":"Y4_QNX1PgFx0","executionInfo":{"status":"ok","timestamp":1769512143434,"user_tz":-330,"elapsed":705,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["db = 0\n","def build_database(question):\n","  parsed_question = parse_question(question)\n","  add_tickers(parsed_question)\n","  time.sleep(1.5)\n","  docs = build_docs(parsed_question[2], parsed_question=parsed_question)\n","\n","  splitter = RecursiveCharacterTextSplitter(\n","      chunk_size=1100,\n","      chunk_overlap=100,\n","  )\n","\n","  chunked_docs = splitter.split_documents(docs)\n","  print(f\"Chunked into {len(chunked_docs)} passages\")\n","  if chunked_docs:\n","    global db\n","    db = FAISS.from_documents(chunked_docs, embedder)\n","    db.save_local(\"faiss_av_index\")\n","  else:\n","    print(\"No documents to chunk or embed. FAISS index will not be created.\")"],"metadata":{"id":"bQD1BCXRNWmw","executionInfo":{"status":"ok","timestamp":1769512143455,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# question = 'Explain the trends is stocks of apple inc'\n","# build_database(question)\n","# query = question\n","# for step in agent.stream(\n","#     {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n","#     stream_mode=\"values\",\n","# ):\n","#     step[\"messages\"][-1].pretty_print()"],"metadata":{"id":"irBD_jsCNCZF","executionInfo":{"status":"ok","timestamp":1769512143464,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}},"collapsed":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","\n","\n","def chat_handler(question, history):\n","  build_database(question)\n","  query = question\n","  partial_text = \"\"\n","  for step in agent.stream(\n","    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n","    stream_mode=\"values\",\n","    ):\n","      partial_text = step[\"messages\"][-1].content\n","      yield partial_text\n","\n","# Launch the interface\n","demo = gr.ChatInterface(chat_handler)\n","demo.queue().launch(\n","    share = True,\n","    show_error = True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"JPNoCOFnYg0J","executionInfo":{"status":"ok","timestamp":1769516754945,"user_tz":-330,"elapsed":1469,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}},"outputId":"93f18bbb-ac96-43f8-eea0-2a6d3e27078c"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n","  self.chatbot = Chatbot(\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://78272c0429561a3ee0.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://78272c0429561a3ee0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"jJeyI1ObZphj","executionInfo":{"status":"ok","timestamp":1769512145784,"user_tz":-330,"elapsed":14,"user":{"displayName":"Vishruth","userId":"17186735987924674674"}}},"execution_count":42,"outputs":[]}]}